\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsfonts, mathrsfs,fancyhdr,syntonly,lastpage,hyperref,enumitem,graphicx, lscape, forloop, url, natbib}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}

\hypersetup{colorlinks=true,urlcolor=black}

\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}

\newcommand{\hh}[1]{{\color{magenta} #1}}
\newcommand{\st}[1]{{\color{red} #1}}

\begin{document}
\lhead{Graph Lineups}
\chead{}
\rhead{Samantha Tyner}

\tableofcontents

\section{Introduction}

Stochastic actor-oriented models (SAOMs) are a set of network models that consider both network and actor effects when determining how and why a network changes over time. Network effects, like reciprocity and outdegree, only consider the ties between actors as important to network change, while actor effects allow for covariate values associated with each actor to influence ties between actors. In the SAOM literature, a network is denoted by $x(t_m)$, has $n$ actors, and for two actors $i \neq j \in \{1, 2, \dots, n\}$, the relationship between them is denoted by $x_ij$. This relationship $x_{ij}$ is equal to 1 if there is a tie between actors $i$ and $j$ and it is 0 if there is not a tie between them. The time component, $t_m$, represents the $m = 1, 2, \dots, M$ points of observation of the network. These networks $x(t_1), \dots, x(t_M)$ are modeled as observations of a continuous-time Markov chain, where most of the steps in the chain are unobserved. 

\par Between any two discrete time points, $t_{m}$ and $t_{m-1}$ for $m = 2, \dots, M$, each actor gets the opportunity to change one of their ties at a rate of $\alpha_{m-1}$. This is due to the properties of the Markov chain, and it also assumes that the rate of change is identical and constant for each actor between $t_{m-1}$ and $t_{m}$. When an actor is given an opportunity to change, it tries to maximize its objective function, $f_i(\beta, x)$, where $x$ is the potential new network state that actor $i$ can reach by changing one of its ties, $x_{ij}$. In model estimation, the parameters to be estimated are $\alpha_1, \dots, \alpha_{M-1}$ and the (possibly vector-valued) $\beta$. The objective function takes the form 

$$ f_i(\beta, x) = \sum_k \beta_k s_{ki}(x)$$ 

where $k = 1, \dots, K$, $K$ the number of non-rate parameters in the models and $s{ki}(x)$ is the corresponding statistic. There are several parameters that can be chosen for use in the objective function. Examples of these parameters and their corresponding statistics are given in Table~\ref{tab:models}. 

\section{Models}

We fit \st{three} different stochastic actor-oriented models to a subset of the 50 actor dataset from the ``Teenage Friends and Lifestyle Study" that is provided on the RSiena webpage.\footnote{\url{http://www.stats.ox.ac.uk/~snijders/siena/s50_data.htm}} We chose to subset the data to decrease the cognitive load on our experiment's subjects. The subset contained actors 20 through 35 and the ties between them, as well as the drinking behavior of each actor at each of the three waves. This specific subset was chosen because it showed somewhat higher connectivity than other subsets, as we've emphasized in the visualizations of the three network adjacency matrices below. For model fitting, we condition on wave 1 and estimate the parameters of our models from the second and third waves.

\begin{figure}
<<get_sm_friends, echo=FALSE, fig.width=8, fig.height=3, message = FALSE, warning = FALSE>>=
source("Code/00e_small_friends.R")
view_rs2$wave <- factor(view_rs2$wave)
levels(view_rs2$wave) <- c("Wave 1", "Wave 2", "Wave 3")
ggplot(data= view_rs2, aes(x = x, y=y)) + 
  geom_tile(aes(fill = as.factor(value))) + 
  scale_fill_manual("X likes Y", labels=c("no", "yes"), 
                    values = c('white', 'black')) +
  geom_rect(data= NULL, inherit.aes = FALSE, color = 'red',
            aes(xmin = 20, xmax = 35, ymin = 20, ymax = 35, fill =NA)) + 
  facet_wrap(~wave) + theme_bw() +
  theme(aspect.ratio=1, axis.text = element_blank(), axis.ticks = element_blank()) 
@
\caption{\label{fig:smallfriends}Adjacency matrices describing friendship relations between 50 students in waves 1,2, and 3 of the friendship study \citep{friendsdata}. The red squares identify the subset we focus on in the remainder.}
\end{figure}

The first wave of the network, which is conditioned on in estimation, is given in Figure~\ref{fig:wave1}.

\begin{figure}
\centering
<<wave1, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, out.width='.6\\linewidth'>>=
library(sna)
library(network)
actual1 <- merge(data.frame(as.edgelist(as.network(fd2.w1))), 
                 data.frame(id = 1:16, drink = drink2[,1]), 
                 by.x = "X1", by.y = "id", all = T)
for (j in 1:nrow(actual1)){
      if (!(actual1$X1[j] %in% actual1$X2) & is.na(actual1$X2[j])){
        actual1$X2[j] <- actual1$X1[j]
      } else {actual1$X2[j] <- actual1$X2[j]}
}
actual2 <- merge(data.frame(as.edgelist(as.network(fd2.w2))), 
                 data.frame(id = 1:16, drink = drink2[,2]), 
                 by.x = "X1", by.y = "id", all = T)
for (j in 1:nrow(actual2)){
      if (!(actual2$X1[j] %in% actual2$X2) & is.na(actual2$X2[j])){
        actual2$X2[j] <- actual2$X1[j]
      } else {actual2$X2[j] <- actual2$X2[j]}
    }
actual1$wave <- 1
actual2$wave <- 2

waves <- rbind(actual1, actual2)
library(geomnet)
actual1$behaviour <- factor(actual1$drink)
levels(actual1$behaviour) <- c("None", "Once or twice a year", "Once a month", "Once a week")
ggplot(data = actual1, aes(from_id = X1, to_id = X2)) + 
  geom_net(label = TRUE, hjust = 0.5, vjust=0.5, size=10,  
           fiteach = T, labelcolour = "grey20", 
           aes(colour = behaviour)) + 
  scale_colour_brewer("Drinking behavior", palette="YlOrRd") +
  theme_net() 

#ggplot(data = waves, aes(from_id = X1, to_id = X2)) + 
#  geom_net(label = TRUE, hjust = -.5, labelcolour = 'black', fiteach = T,
#           aes(color = as.factor(drink))) + 
#  theme_net() + theme(panel.background = element_rect(fill = "white", color = 'black')) + facet_wrap(~wave)
@
\caption{\label{fig:wave1} Network of friendships of wave 1 of the subset of students marked in Figure~\ref{fig:smallfriends}. }
\end{figure}

<<modelfit, echo=FALSE, results = 'hide', message=FALSE, warning = FALSE, cache = T>>=
source("Code/03c_complete_lineup_creation.R")
lineup1 <- create_smfriend_lu(null_eff_struct = null_model_eff2, test_eff_struct = eff_models_smallFriends[[39]], M = 3)
@

The two models we fit are a ``null model" (model $M_1$) and two ``alternative models" (model $M_2$ and $M_3$). The null model only includes the default parameters that are included in the RSiena estimation: the reciprocity and outdegree parameters. The alternative model $M_2$ includes one additional covariate parameter that was determined to be significant by the Wald test in the RSienaTest package, while the alternative model $M_3$ includes one additional structural parameter whose significance was determined in the same way. Details on these effects are given in Table~\ref{tab:models}.

<<readsimu, echo=FALSE>>=
 nulls <- read.csv("Data/distribution_null_model.csv")
# names(nulls)[-1] <- c("alpha1", "alpha2", "beta1", "beta2")
# nulls$Sim <- 1:nrow(nulls)
# nulls$Model <- "M1"
# 
 alt <- read.csv("Data/distribution_jumpTT_model.csv")
# names(alt)[-1] <- c("alpha1", "alpha2", "beta1", "beta2", "beta3")
# alt$Sim <- 1:nrow(alt)
# alt$Model <- "M2"
# 
 alt2nd <- read.csv("Data/distribution_dblpairs_model.csv")
# names(alt2nd)[-1] <- c("alpha1", "alpha2", "beta1", "beta2", "beta4")
# alt2nd$Sim <- 1:nrow(alt2nd)
# alt2nd$Model <- "M3"
# 
# alt2 <- gather(alt, parameter, estimate, 2:6)
# null2 <- gather(nulls, parameter, estimate, 2:5)
# alt2nd2 <- gather(alt2nd, parameter, estimate, 2:6)
# 
# simu <- rbind(alt2[,-1], null2[,-1])
# write.csv(simu, "Data/simulation-1000-M1-M2.csv", row.names=FALSE)


simu2 <- read.csv("Data/simulation-1000-M1-M2-M3.csv")
means <- simu2 %>% group_by(Model, parameter) %>% summarize(
  mean = mean(estimate)
)
library(dplyr)
null_mod_sv <- as.numeric(nulls[,-c(1,6,7)] %>% summarise_each(funs(mean)))
alt_mod_sv <- as.numeric(alt[,-c(1, 7,8)] %>% summarise_each(funs(mean)))
alt_mod2_sv <- as.numeric(alt2nd[,-c(1,7,8)] %>% summarise_each(funs(mean)))
@

\begin{table}[h]
\caption{\label{tab:models}Parameters and estimates of models $M_1$, $M_2$, and $M_3$. Estimates are the mean of 1000 iterations of the model estimates. The lineups that follow are simulated from models using these values.}
\centering
\scalebox{0.8}{
\begin{tabular}{lccrrr}
Effect name & Parameter & Corresponding Statistic & $M_1$  & $M_2$  & $M_3$ \\
\hline
\hline
Rate 1 (wave 1 $\rightarrow$ 2) & $\alpha_1$ & $\sum\limits_{i,j = 1 i\neq j}^n (x_{ij}(t_2) - x_{ij}(t_1))^2 $ & 
\Sexpr{round(null_mod_sv[1], 2)} &
\Sexpr{round(alt_mod_sv[1], 2)} & 
\Sexpr{round(alt_mod2_sv[1], 2)} 
\\
Rate 2 (wave 2 $\rightarrow$ 3) & $\alpha_2$ & $\sum\limits_{i,j = 1 i\neq j}^n (x_{ij}(t_3) - x_{ij}(t_2))^2 $ & 
\Sexpr{round(null_mod_sv[2], 2)} &
\Sexpr{round(alt_mod_sv[2], 2)} & 
\Sexpr{round(alt_mod2_sv[2], 2)}
\\
Outdegree & $\beta_1$ & $s_{i1}(x) = \sum\limits_{j=1}^n x_{ij}$ & 
\Sexpr{round(null_mod_sv[3], 2)} &
\Sexpr{round(alt_mod_sv[3], 2)} & 
\Sexpr{round(alt_mod2_sv[3], 2)}
\\
Reciprocity & $\beta_2$ & $s_{i2}(x) = \sum\limits_{j=1}^n x_{ij}x_{ji}$ & \Sexpr{round(null_mod_sv[4], 2)} &
\Sexpr{round(alt_mod_sv[4], 2)} & 
\Sexpr{round(alt_mod2_sv[4], 2)}
\\
Jumping Transitive Triplets & $\beta_3$ & $s_{i3}(x) = \sum\limits_{\forall j\neq h} x_{ij}x_{ih}x_{hj} \mathbb{I}(v_i = v_h \neq v_j)$ & -- & 
\Sexpr{round(alt_mod_sv[5], 2)} & -- \\
\# doubly achieved distances & $\beta_4$ & $s_{i4}(x) = |\{j : x_{ij} = 0, \sum\limits_h x_{ih}x_{hj} \geq 2\}|$ & -- & -- &
\Sexpr{round(alt_mod2_sv[5], 2)}
\end{tabular}}
\end{table}


\begin{figure}
\centering
<<hist-estimates, dependson='read-simu', echo=FALSE, fig.width=8, fig.height=5, out.width='.8\\linewidth'>>=
qplot(data=simu2, estimate, fill=Model, geom="density", alpha=I(0.65)) + facet_wrap(~parameter, scales="free") + theme_bw()
@
\caption{\label{fig:hist-simulations}Histogram of the distribution of model parameters based on 1,000 simulation runs. Model parameter $\beta_3$ for jumping transitive triplets in model $M_2$ is significantly different from zero, but its inclusion also leads to significant changes in the  other model parameters of model $M_1$. The parameter $\beta_4$ for doubly acheived distances is also significantly different from zero, but has larger variance. The inclusion of $\beta_4$ also changes the estimates of the other model parameters, but not as much as the inclusion of $\beta_3$.}
\end{figure}

After estimating the parameters in each of these models, we simulate from them to obtain realizations of each of the models. The objective function for each actor in each model is given below. 
  \begin{align*}
  f^{M_1}_{i}(x) & = \hat{\beta}_1^{M_1}s_{i1}(x) +  \hat{\beta}_2^{M_1}s_{i2}(x) \\
  f^{M_2}_{i}(x) & = \hat{\beta}_1^{M_2}s_{i1}(x) +  \hat{\beta}_2^{M_2}s_{i2}(x) + \hat{\beta}_3^{M_2}s_{i3}(x) \\
  f^{M_3}_{i}(x) & = \hat{\beta}_1^{M_3}s_{i1}(x) +  \hat{\beta}_2^{M_3}s_{i2}(x) + \hat{\beta}_4^{M_3}s_{i4}(x) 
  \end{align*}
The rate parameters, $\alpha_1$ and $\alpha_2$ represent how many opportunities for change each actor gets when moving from wave 1 to 2 and from wave 2 to 3, respectively. The outdegree parameter, $\beta_1$, represents how likely an actor is to change outgoing ties. If the estimate, $\hat{\beta}_1$, is positive, the actor is more likely to create outgoing ties, while a negative estimate leads the actor to deleting outgoing ties. This effect is highly correlated with the reciprocity parameter, $\beta_2$. A negative estimate of this parameter implies that the actor is discouraged from reciprocating its incoming ties, while a positive estimate implies that the actor is encouraged to reciprocate all ties. The additional parameter in $M_2$, $\beta_3$, is a covariate parameter. The covariate in this model is the drinking behaviour of the 16 students in our data. The possible values are 1, 2, 3, and 4, which means the student drinks never, once or twice a year, once a month, or once a week. This jumping transitive triplet effect impacts the transitive closure of actors from different groups. Thus, a positive estimate encourages transitive closure when one of three actors is in a different covariate group than the other two, while a negative estimate discourages this behavior. An example of this type of closure is given in Figure~\ref{fig:jtt}. With the directed edges we also distinguish between 'i likes j' and 'j likes i'. Finally, the doubly achieved distances effect is defined by the number of actors to whom actor $i$ is not directly tied, and tied through two paths via at least two intermediaries. This is a structural effect, like the density and reciprocity effects. A positive coefficient value encourages indirect ties, while a negative value discourages the formation of indirect ties. 

\begin{figure}
\begin{subfigure}[t]{.45\textwidth}
\caption{Realization of a jumping transitive triplet, where $i$ is the focal actor, $j$ is the target actor, and $h$ is the intermediary. The group of the actors is represented by the shape of the node.}
<<jtt, echo=FALSE, fig.width=2, fig.height=2, message = FALSE, warning = FALSE, fig.align='center'>>=
jTTe <- data.frame(from = c('i', 'i', 'h'), to = c('h', 'j', 'j'))
jTTn <- data.frame(id = letters[8:10], group = c(1,1,2))

jTT <- merge(jTTe, jTTn, by.x = 'from', by.y = "id", all = T)

set.seed(12345) 
ggplot(data = jTT, aes(from_id = from, to_id = to)) + 
  geom_net(aes(shape = as.factor(group)), directed = T, label = T, 
           labelcolour='grey80',vjust = 0.5, hjust =0.5, arrowgap = .15, 
           colour = 'black', size=10, 
           ecolour = c("red", "grey40", "grey40", "grey40")) + 
  expand_limits(x=c(-0.1,1.1), y=c(-0.1,1.1)) +
  theme_net() +
  theme(legend.position = "none")
@
\end{subfigure}\hfill
\begin{subfigure}[t]{.45\textwidth}
\caption{Doubly achieved distance between actors $i$ and $k$.}
<<dab, echo=FALSE, fig.width=2, fig.height=2, message = FALSE, warning = FALSE, fig.align='center'>>=
dade <- data.frame(from = c('i', 'i', 'h', 'j'), to = c('h', 'j', 'k', 'k'))
dadn <- data.frame(id = letters[8:11], group = c(1,1,1,1))

dad <- merge(dade, dadn, by.x = 'from', by.y = "id", all = T)

set.seed(12345) 
ggplot(data = dad, aes(from_id = from, to_id = to)) + 
  geom_net(aes(shape = as.factor(group)), directed = T, label = T, labelcolour='grey80',vjust = 0.5, hjust =0.5, arrowgap = .15, colour = 'black', size=10) + 
  expand_limits(x=c(-0.1,1.1), y=c(-0.1,1.1)) +
  theme_net() +
  theme(legend.position = "none")
@
\end{subfigure}
\caption{\label{fig:structures}Structural newtwork effects. On the left, a jumping transitive triplet (JTT). On the right, a doubly achieved distance between $i$ and $k$.}
\end{figure}

\section{Lineup Simulation}

\hh{Needs more specifics: how many lineups were created for each model?}

\hh{At the moment we are just considering models M2 and M3 for an inclusion in the lineup study. We are trying to nail down what to include and what not to include in the experiment.  }

To create the lineups that will be used in our experiment, we used the values given in Table~\ref{tab:models} as starting values in simulation. For each lineup simulated, the same default RSiena algorithm was used as was used to generate the fitted models with the exception that the algorithm only simulated from the given set of parameters. Each lineup and plot within lineup was generated idependent of all the others.


\section{Parameter Estimation from Lineups}

After the lineups were created, we re-fit each of our three models to each graph in each lineup. 

\hh{Questions that should be answered in this section:

1. Why do we want to get the parameters for each model? 
\st{We fit all three models to every plot in the lineups. Fitting all models to all lineup plots allows us to gauge tha ability of the parameter estimates to provide a measure of lineup identification difficulty. XXX ? not quite sure ? XXX For instance, when comparing models 1 and 2 in a lineup, the estimates from fitting model 2 to plots which were simulated from model 2 should be significantly different from the model 2 estimates from plots simulated from model 1. The smaller the difference between these estimates, the harder it should be to identify the different model in the lineup. XXX IDEA: should we consider some sort of distance metric comparing all estimates from the models at once in addition to the differences in the $\beta_3$/$\beta_4$ values? XXX}

2. How is the fitting done, exactly?
\st{XXX get into nitty gritty from RSiena model XXX }

4. What parameters are in the output?
% ST: add how convergence is calculated. from RSiena manual. 
5. What are the results?
}
\begin{figure}
<<results1, fig.width=8, fig.height=6, out.width='\\linewidth', echo = FALSE, warning = FALSE>>=
load("Data/lus_ests_truth.rda")
lus_ests_truth$param_name <- 
  factor(lus_ests_truth$param_name,
    levels = c("rate", "outdegree (density)", "reciprocity",
               "transitive triplets jumping alcohol2",
               "number pairs at doubly achieved distance 2"))                                
l1 <- levels(lus_ests_truth$param_name)
l1 <- stringr::str_trim(gsub("2","", l1))
l1[5] <- "#pairs at doubly achieved distance"

# subset on ones that are actually converged. 
ggplot(data = lus_ests_truth) + 
  geom_vline(aes(xintercept = 0), colour="grey50") +
  geom_density(alpha = .5, aes(x = param_est, fill = param_name)) + 
  facet_grid(model~true_model, scales = 'free', 
             labeller = "label_both") + xlim(c(-20,20)) +
  theme_bw() + 
  scale_fill_brewer("Parameter", palette="Dark2",
     labels=c(bquote(paste(alpha,": ", .(l1[1]), sep="")), 
              bquote(paste(beta[1],": ", .(l1[2]), sep="")),
              bquote(paste(beta[2],": ", .(l1[3]), sep="")),
              bquote(paste(beta[3],": ", .(l1[4]), sep="")),
              bquote(paste(beta[4],": ", .(l1[5]), sep="")))) +
  theme(legend.position = "bottom") +
  xlab("Parameter Estimate") + 
  guides(fill = guide_legend(nrow = 3, byrow = TRUE))
@
\caption{\label{fig:comparison} Comparison of model estimates under all three models under investigation.}
\end{figure}

Figure~\ref{fig:comparison} shows an overview of model estimates for each simulated data set. What we expect to see is that estimates do not change values (much) if they are estimated under a model different from the one they are generated from. This is true for all data sets estimated under model $M_1$ independently of which model they were generated from (top row of Figure~\ref{fig:comparison}). For data fitted under model $M_2$ we see that parameter $\beta_3$ (jumping transitive triplets) are estimated to be about zero, if the data is generated from models $M_1$ and $M_3$.
For model $M_2$, parameter $\beta_3$ is estimated to be significantly different from zero in almost all cases \hh{(XXX how many exactly? XXX)}. This coincides with our expectation.

However, the bottom row of Figure~\ref{fig:comparison} shows that independently of which model data is generated from, $\beta_4$, the number of pairs at doubly achieved distance, is estimated to be significantly different from zero in a large number of cases (about half in data generated from model $M_2$ and more than that in model $M_1$). While $\beta_4$ is a highly significant parameter in model $M_3$, this questions the way that parameters are fitted and tells us that we are not likely to be able to visually distinguish between data generated from model $M_3$ and data generated from models $M_1$ and $M_2$. We might, however, be able to distinguish between data sets for which $\beta_4$ is estimated to be significantly different from zero and non-significant ones. \hh{XXX can we see differences in the pilot study?}

\hh{
6. How do the results influence our decision for the lineups?
}
The strong influence of the inclusion of $\beta_4$ in model 3 has made any comparison between model 1 and model 3 impossible. The $\beta_4$ estimate is always significantly greater than zero in fitted models that converged. Thus, $\beta_4$ should have been included from the beginning.
% at end of param est we know that model m3 is useless. m3 messes with structure of m1. should have been in cluded in all of the models. nice & important but doesn't help for lineup study

%  results from the the pilot study. how do estimates combine with pilot study ? have 10 non-m3 ones that are good. also want to see that m1 v m3 is way worse than m1 v m2. now have a reason for m1 v m3 is so bad. m1 v m3 ids should be NO GOOD. 



\section{Results from the pilot study}

\hh{Big goal: Can we derive measures from the model estimates or the visual representation (ie. the network structure) that help us determine which lineups are more difficult than others, i.e. based on these estimates, how relaibly can we predict which panel will be picked from a lineup? 
XXX For that, we could also calculate the number of JTTs in each network - use `jtt` for that.}


\hh{Littler goal: evaluate pilot study and see whether the results line up with the conjectures made in the previous section.}


\hh{The pilot study consisted of an evaluation of a set of 20 lineups by 11 volunteers. For each of the model situations ($M_1$ vs $M_2$, $M_2$ vs $M_1$, $M_1$ vs $M_3$ and $M_3$ vs $M_1$) one lineup of size $m = 3, 6, 9, 12$ was used. Overall, the number of data identifications in the lineups was very low (34 out of 220 evaluations). Participants identified the data plot in two to four of the lineups they evaluated. The mode was three data identifications. }
\paragraph{Suitability of $M_3$ in lineups:}
\begin{figure}
\centering
<<data-picks, echo=FALSE, fig.width=10, fig.height=5, out.width='0.85\\linewidth'>>=
pdffiles <- dir("GGExperimentApr28/", pattern="pdf")
pdffiles <- gsub(".pdf","",pdffiles)
#pdffiles <- gsub("-m","",pdffiles)
#pdffiles <- gsub("-rep","",pdffiles)

dframe <- strsplit(pdffiles, split=" ") %>% plyr::ldply(function(x) x)
names(dframe) <- c("stimulus", "lineupid")

results <- read.csv("GGExperimentApr28/responses_GGExpApr28.csv")
lus <- results %>% group_by(Lineup, ChosenLU) %>% summarize(
  tally = n(),
  data = Answer[1],
  reason = paste(Reasoning, collapse="|")
)
names(lus)[2] <- "panel"

dframe_res <- merge(dframe, lus, all=TRUE, by.x="stimulus", by.y="Lineup")
dframe_res$data_pick <- with(dframe_res, data==panel)
dframe_res$model <- factor(gsub("(.*)-m.*", "\\1", dframe_res$lineupid))
levels(dframe_res$model) <- c("M1 vs M2",  "M1 vs M3", "M3 vs M1", "M2 vs M1")
dframe_res$model <- factor(dframe_res$model, levels = c("M1 vs M2",  "M2 vs M1", "M1 vs M3", "M3 vs M1"))
dframe_res$label <- gsub(".*-(m.*)", "\\1", dframe_res$lineupid)

dframe_res$data_pick <- factor(dframe_res$data_pick, levels=c("TRUE", "FALSE"))
dframe_res$res <- factor(dframe_res$data_pick, levels=c("TRUE", "FALSE"))
qplot(label, weight=tally, fill=data_pick, data=dframe_res) +
  facet_grid(.~model, scales="free", space="free") + theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust=1)) + 
  scale_fill_brewer("Data panel chosen", palette="Set1", na.value="grey80") + xlab("Lineup")
@
\caption{\label{fig:data-picks}Barchart summarizing the number of responses from the pilot study by model and lineup. Color shows the number of times the data panel was chosen from the lineup. Clearly, the first two sets of lineups ($M_1$ vs $M_2$ and $M_2$ vs $M_1$) have on average higher number of data identifications. }
\end{figure}

\hh{Figure~\ref{fig:data-picks} shows barcharts of responses from the pilot study detailing the number of data identifications in each lineup. }
\hh{It is more difficult to identify the data plot in lineups of graphs based on data from models $M_1$ and $M_3$ than  in lineups of graphs based on data from models $M_1$ and $M_2$.
}

\bibliographystyle{apalike}
\bibliography{lineuppaperbib}

\section{Model $M_1$ versus $M_2$ lineup size 3}
\newcounter{k}
\forloop{k}{1}{\value{k} < 21}{smallfriends-m-3-rep-\arabic{k}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-m-3-rep-\arabic{k}} \\ }

\section{Model $M_1$ versus $M_2$ lineup size 6}
\newcounter{k1}
\forloop{k1}{1}{\value{k1} < 21}{
Lineup-Images/pdfs/smallfriends-m-6-rep-\arabic{k1}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-m-6-rep-\arabic{k1}} \\ }

\section{Model $M_1$ versus $M_2$ lineup size 9}
\newcounter{k2}
\forloop{k2}{1}{\value{k2} < 21}{Lineup-Images/pdfs/smallfriends-m-9-rep-\arabic{k2}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-m-9-rep-\arabic{k2}} \\ }

\section{Model $M_1$ versus $M_2$ lineup size 12}
\newcounter{k3}
\forloop{k3}{1}{\value{k3} < 21}{Lineup-Images/pdfs/smallfriends-m-12-rep-\arabic{k3}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-m-12-rep-\arabic{k3}} \\ }

\section{Model $M_1$ versus $M_2$ lineup size 16}
\newcounter{k4}
\forloop{k4}{1}{\value{k4} < 21}{smallfriends-m-16-rep-\arabic{k4}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-m-16-rep-\arabic{k4}} \\ }

\section{Model $M_2$ versus $M_1$ lineup size 3}
\newcounter{k5}
\forloop{k5}{1}{\value{k5} < 21}{smallfriends-rev-m-3-rep-\arabic{k5}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-rev-m-3-rep-\arabic{k5}} \\ }

\section{Model $M_2$ versus $M_1$ lineup size 6}
\newcounter{k6}
\forloop{k6}{1}{\value{k6} < 21}{smallfriends-rev-m-6-rep-\arabic{k6}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-rev-m-6-rep-\arabic{k6}} \\ }

\section{Model $M_2$ versus $M_1$ lineup size 9}
\newcounter{k7}
\forloop{k7}{1}{\value{k7} < 21}{smallfriends-rev-m-9-rep-\arabic{k7}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-rev-m-9-rep-\arabic{k7}} \\ }

\section{Model $M_2$ versus $M_1$ lineup size 12}
\newcounter{k8}
\forloop{k8}{1}{\value{k8} < 21}{smallfriends-rev-m-12-rep-\arabic{k8}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-rev-m-12-rep-\arabic{k8}} \\ }

\section{Model $M_2$ versus $M_1$ lineup size 16}
\newcounter{k9}
\forloop{k9}{1}{\value{k9} < 21}{smallfriends-rev-m-16-rep-\arabic{k9}\newline
\includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-rev-m-16-rep-\arabic{k9}} \\ }

% \section{Model $M_1$ versus $M_3$ lineup size 3}
% \newcounter{k10}
% \forloop{k10}{1}{\value{k10} < 21}{smallfriends-eff2-m-3-rep-\arabic{k10}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-m-3-rep-\arabic{k10}} \\ }
% 
% \section{Model $M_1$ versus $M_3$ lineup size 6}
% \newcounter{k11}
% \forloop{k11}{1}{\value{k11} < 21}{smallfriends-eff2-m-6-rep-\arabic{k11}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-m-6-rep-\arabic{k11}} \\ }
% 
% \section{Model $M_1$ versus $M_3$ lineup size 9}
% \newcounter{k12}
% \forloop{k12}{1}{\value{k12} < 21}{smallfriends-eff2-m-9-rep-\arabic{k12}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-m-9-rep-\arabic{k12}} \\ }
% 
% \section{Model $M_1$ versus $M_3$ lineup size 12}
% \newcounter{k13}
% \forloop{k13}{1}{\value{k13} < 21}{smallfriends-eff2-m-12-rep-\arabic{k13}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-m-12-rep-\arabic{k13}} \\ }
% 
% \section{Model $M_1$ versus $M_3$ lineup size 16}
% \newcounter{k14}
% \forloop{k14}{1}{\value{k14} < 21}{smallfriends-eff2-m-16-rep-\arabic{k14}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-m-16-rep-\arabic{k14}} \\ }
% 
% \section{Model $M_3$ versus $M_1$ lineup size 3}
% \newcounter{k15}
% \forloop{k15}{1}{\value{k15} < 21}{smallfriends-eff2-rev-m-3-rep-\arabic{k15}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-rev-m-3-rep-\arabic{k15}} \\ }
% 
% \section{Model $M_3$ versus $M_1$ lineup size 6}
% \newcounter{k16}
% \forloop{k16}{1}{\value{k16} < 21}{smallfriends-eff2-rev-m-6-rep-\arabic{k16}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-rev-m-6-rep-\arabic{k16}} \\ }
% 
% \section{Model $M_3$ versus $M_1$ lineup size 9}
% \newcounter{k17}
% \forloop{k17}{1}{\value{k17} < 21}{smallfriends-eff2-rev-m-9-rep-\arabic{k17}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-rev-m-9-rep-\arabic{k17}} \\ }
% 
% \section{Model $M_3$ versus $M_1$ lineup size 12}
% \newcounter{k18}
% \forloop{k18}{1}{\value{k18} < 21}{smallfriends-eff2-rev-m-12-rep-\arabic{k18}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-rev-m-12-rep-\arabic{k18}} \\ }

% \section{Model $M_3$ versus $M_1$ lineup size 16}
% \newcounter{k19}
% \forloop{k19}{1}{\value{k19} < 21}{smallfriends-eff2-rev-m-16-rep-\arabic{k19}\newline
% \includegraphics[width = \textwidth]{Lineup-Images/pdfs/smallfriends-eff2-rev-m-16-rep-\arabic{k19}} \\ }


\end{document}